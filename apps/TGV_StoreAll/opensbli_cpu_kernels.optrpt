Intel(R) Advisor can now assist with vectorization and show optimization
  report messages with your source code.
See "https://software.intel.com/en-us/intel-advisor-xe" for details.


    Report from: Interprocedural optimizations [ipo]

INLINING OPTION VALUES:
  -inline-factor: 100
  -inline-min-size: 30
  -inline-max-size: 230
  -inline-max-total-size: 2000
  -inline-max-per-routine: 10000
  -inline-max-per-compile: 500000


Begin optimization report for: ops_par_loop_opensbliblock00Kernel087(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel087(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)) [1] ./MPI_OpenMP/opensbliblock00Kernel087_cpu_kernel.cpp(11,30)
  -> INLINE: (134,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (135,94) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (136,92) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (137,94) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (138,94) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (160,77) std::pow<double, int>(double, int)
     {{ Inlining of routines from system headers is omitted. Use -qopt-report=3 to view full report. }}
  -> INLINE: (162,8) std::pow<double, int>(double, int)
     {{ Inlining of routines from system headers is omitted. Use -qopt-report=3 to view full report. }}
  -> INLINE: (164,10) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (166,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (168,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (170,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (172,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (172,43) std::pow<double, int>(double, int)
     {{ Inlining of routines from system headers is omitted. Use -qopt-report=3 to view full report. }}
  -> INLINE: (172,56) std::pow<double, int>(double, int)
     {{ Inlining of routines from system headers is omitted. Use -qopt-report=3 to view full report. }}
  -> INLINE: (172,69) std::pow<double, int>(double, int)
     {{ Inlining of routines from system headers is omitted. Use -qopt-report=3 to view full report. }}


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel087_cpu_kernel.cpp(119,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel087_cpu_kernel.cpp(120,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel087_cpu_kernel.cpp(132,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel087_cpu_kernel.cpp(132,7)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel087_cpu_kernel.cpp(28,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel087_cpu_kernel.cpp(28,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel087_cpu_kernel.cpp(28,35):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel087_cpu_kernel.cpp(28,41):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel087_cpu_kernel.cpp(28,47):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel087_cpu_kernel.cpp(28,53):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel087_cpu_kernel.cpp(11,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel087PKcP14ops_block_coreiPi7ops_argS4_S4_S4_S4_S4_] ./MPI_OpenMP/opensbliblock00Kernel087_cpu_kernel.cpp:11

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   42[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm27]
        
    Routine temporaries
        Total         :     616
            Global    :     151
            Local     :     465
        Regenerable   :     150
        Spilled       :      75
        
    Routine stack
        Variables     :     532 bytes*
            Reads     :      26 [3.22e-04 ~ 0.0%]
            Writes    :      41 [8.70e-04 ~ 0.0%]
        Spills        :     872 bytes*
            Reads     :     130 [2.04e+01 ~ 20.4%]
            Writes    :      91 [1.31e+01 ~ 13.1%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel081(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel081(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)) [2] ./MPI_OpenMP/opensbliblock00Kernel081_cpu_kernel.cpp(11,16)
  -> INLINE: (117,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (118,94) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (119,92) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (120,94) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (121,94) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (123,10) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (123,27) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (125,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (125,36) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (127,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (127,31) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (129,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (129,31) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (131,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (131,29) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (133,10) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (133,27) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (135,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (135,36) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (137,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (137,31) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (139,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (139,31) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (141,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (141,29) ACC<double>::operator()(ACC<double> *, int, int, int)


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel081_cpu_kernel.cpp(103,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel081_cpu_kernel.cpp(104,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel081_cpu_kernel.cpp(116,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel081_cpu_kernel.cpp(116,7)
   <Remainder loop for vectorization>
      remark #15335: remainder loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel081_cpu_kernel.cpp(27,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel081_cpu_kernel.cpp(27,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel081_cpu_kernel.cpp(27,35):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel081_cpu_kernel.cpp(27,41):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel081_cpu_kernel.cpp(27,47):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel081_cpu_kernel.cpp(11,16):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel081PKcP14ops_block_coreiPi7ops_argS4_S4_S4_S4_] ./MPI_OpenMP/opensbliblock00Kernel081_cpu_kernel.cpp:11

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   26[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm11]
        
    Routine temporaries
        Total         :     461
            Global    :      95
            Local     :     366
        Regenerable   :     141
        Spilled       :      35
        
    Routine stack
        Variables     :     476 bytes*
            Reads     :      20 [7.31e-04 ~ 0.0%]
            Writes    :      35 [2.58e-03 ~ 0.0%]
        Spills        :     320 bytes*
            Reads     :      72 [1.35e-02 ~ 0.0%]
            Writes    :      49 [8.76e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel082(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel082(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)) [3] ./MPI_OpenMP/opensbliblock00Kernel082_cpu_kernel.cpp(11,16)
  -> INLINE: (117,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (118,94) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (119,92) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (120,94) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (121,94) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (123,10) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (123,26) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (125,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (125,35) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (127,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (127,30) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (129,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (129,30) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (131,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (131,28) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (133,10) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (133,26) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (135,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (135,35) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (137,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (137,30) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (139,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (139,30) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (141,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (141,28) ACC<double>::operator()(ACC<double> *, int, int, int)


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel082_cpu_kernel.cpp(103,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel082_cpu_kernel.cpp(104,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel082_cpu_kernel.cpp(116,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel082_cpu_kernel.cpp(116,7)
   <Remainder loop for vectorization>
      remark #15335: remainder loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel082_cpu_kernel.cpp(27,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel082_cpu_kernel.cpp(27,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel082_cpu_kernel.cpp(27,35):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel082_cpu_kernel.cpp(27,41):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel082_cpu_kernel.cpp(27,47):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel082_cpu_kernel.cpp(11,16):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel082PKcP14ops_block_coreiPi7ops_argS4_S4_S4_S4_] ./MPI_OpenMP/opensbliblock00Kernel082_cpu_kernel.cpp:11

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   26[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm11]
        
    Routine temporaries
        Total         :     461
            Global    :      95
            Local     :     366
        Regenerable   :     141
        Spilled       :      35
        
    Routine stack
        Variables     :     476 bytes*
            Reads     :      20 [7.31e-04 ~ 0.0%]
            Writes    :      35 [2.58e-03 ~ 0.0%]
        Spills        :     320 bytes*
            Reads     :      72 [1.35e-02 ~ 0.0%]
            Writes    :      49 [8.76e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel083(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel083(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)) [4] ./MPI_OpenMP/opensbliblock00Kernel083_cpu_kernel.cpp(11,16)
  -> INLINE: (117,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (118,94) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (119,92) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (120,94) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (121,94) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (123,10) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (123,27) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (125,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (125,31) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (127,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (127,36) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (129,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (129,31) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (131,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (131,29) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (133,10) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (133,27) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (135,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (135,31) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (137,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (137,36) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (139,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (139,31) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (141,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (141,29) ACC<double>::operator()(ACC<double> *, int, int, int)


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel083_cpu_kernel.cpp(103,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel083_cpu_kernel.cpp(104,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel083_cpu_kernel.cpp(116,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel083_cpu_kernel.cpp(116,7)
   <Remainder loop for vectorization>
      remark #15335: remainder loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel083_cpu_kernel.cpp(27,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel083_cpu_kernel.cpp(27,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel083_cpu_kernel.cpp(27,35):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel083_cpu_kernel.cpp(27,41):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel083_cpu_kernel.cpp(27,47):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel083_cpu_kernel.cpp(11,16):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel083PKcP14ops_block_coreiPi7ops_argS4_S4_S4_S4_] ./MPI_OpenMP/opensbliblock00Kernel083_cpu_kernel.cpp:11

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   26[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm11]
        
    Routine temporaries
        Total         :     506
            Global    :     115
            Local     :     391
        Regenerable   :     141
        Spilled       :      62
        
    Routine stack
        Variables     :     476 bytes*
            Reads     :      20 [3.87e-04 ~ 0.0%]
            Writes    :      35 [1.37e-03 ~ 0.0%]
        Spills        :     536 bytes*
            Reads     :     127 [3.94e+01 ~ 39.4%]
            Writes    :      79 [9.12e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel084(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel084(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)) [5] ./MPI_OpenMP/opensbliblock00Kernel084_cpu_kernel.cpp(11,16)
  -> INLINE: (117,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (118,94) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (119,92) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (120,94) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (121,94) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (123,10) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (123,26) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (125,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (125,30) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (127,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (127,35) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (129,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (129,30) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (131,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (131,28) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (133,10) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (133,26) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (135,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (135,30) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (137,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (137,35) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (139,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (139,30) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (141,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (141,28) ACC<double>::operator()(ACC<double> *, int, int, int)


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel084_cpu_kernel.cpp(103,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel084_cpu_kernel.cpp(104,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel084_cpu_kernel.cpp(116,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel084_cpu_kernel.cpp(116,7)
   <Remainder loop for vectorization>
      remark #15335: remainder loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel084_cpu_kernel.cpp(27,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel084_cpu_kernel.cpp(27,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel084_cpu_kernel.cpp(27,35):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel084_cpu_kernel.cpp(27,41):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel084_cpu_kernel.cpp(27,47):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel084_cpu_kernel.cpp(11,16):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel084PKcP14ops_block_coreiPi7ops_argS4_S4_S4_S4_] ./MPI_OpenMP/opensbliblock00Kernel084_cpu_kernel.cpp:11

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   26[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm11]
        
    Routine temporaries
        Total         :     506
            Global    :     115
            Local     :     391
        Regenerable   :     141
        Spilled       :      62
        
    Routine stack
        Variables     :     476 bytes*
            Reads     :      20 [3.87e-04 ~ 0.0%]
            Writes    :      35 [1.37e-03 ~ 0.0%]
        Spills        :     536 bytes*
            Reads     :     127 [3.94e+01 ~ 39.4%]
            Writes    :      79 [9.12e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel085(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel085(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)) [6] ./MPI_OpenMP/opensbliblock00Kernel085_cpu_kernel.cpp(11,16)
  -> INLINE: (117,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (118,94) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (119,92) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (120,94) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (121,94) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (123,10) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (123,27) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (125,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (125,31) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (127,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (127,31) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (129,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (129,36) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (131,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (131,29) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (133,10) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (133,27) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (135,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (135,31) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (137,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (137,31) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (139,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (139,36) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (141,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (141,29) ACC<double>::operator()(ACC<double> *, int, int, int)


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel085_cpu_kernel.cpp(103,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel085_cpu_kernel.cpp(104,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel085_cpu_kernel.cpp(116,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel085_cpu_kernel.cpp(116,7)
   <Remainder loop for vectorization>
      remark #15335: remainder loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel085_cpu_kernel.cpp(27,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel085_cpu_kernel.cpp(27,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel085_cpu_kernel.cpp(27,35):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel085_cpu_kernel.cpp(27,41):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel085_cpu_kernel.cpp(27,47):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel085_cpu_kernel.cpp(11,16):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel085PKcP14ops_block_coreiPi7ops_argS4_S4_S4_S4_] ./MPI_OpenMP/opensbliblock00Kernel085_cpu_kernel.cpp:11

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   26[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm11]
        
    Routine temporaries
        Total         :     516
            Global    :     115
            Local     :     401
        Regenerable   :     141
        Spilled       :      65
        
    Routine stack
        Variables     :     476 bytes*
            Reads     :      20 [3.87e-04 ~ 0.0%]
            Writes    :      35 [1.37e-03 ~ 0.0%]
        Spills        :     560 bytes*
            Reads     :     127 [3.94e+01 ~ 39.4%]
            Writes    :      77 [9.07e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel086(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel086(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)) [7] ./MPI_OpenMP/opensbliblock00Kernel086_cpu_kernel.cpp(11,16)
  -> INLINE: (117,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (118,94) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (119,92) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (120,94) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (121,94) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (123,10) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (123,26) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (125,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (125,30) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (127,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (127,30) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (129,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (129,35) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (131,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (131,28) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (133,10) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (133,26) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (135,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (135,30) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (137,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (137,30) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (139,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (139,35) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (141,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (141,28) ACC<double>::operator()(ACC<double> *, int, int, int)


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel086_cpu_kernel.cpp(103,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel086_cpu_kernel.cpp(104,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel086_cpu_kernel.cpp(116,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel086_cpu_kernel.cpp(116,7)
   <Remainder loop for vectorization>
      remark #15335: remainder loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel086_cpu_kernel.cpp(27,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel086_cpu_kernel.cpp(27,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel086_cpu_kernel.cpp(27,35):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel086_cpu_kernel.cpp(27,41):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel086_cpu_kernel.cpp(27,47):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel086_cpu_kernel.cpp(11,16):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel086PKcP14ops_block_coreiPi7ops_argS4_S4_S4_S4_] ./MPI_OpenMP/opensbliblock00Kernel086_cpu_kernel.cpp:11

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   26[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm11]
        
    Routine temporaries
        Total         :     516
            Global    :     115
            Local     :     401
        Regenerable   :     141
        Spilled       :      65
        
    Routine stack
        Variables     :     476 bytes*
            Reads     :      20 [3.87e-04 ~ 0.0%]
            Writes    :      35 [1.37e-03 ~ 0.0%]
        Spills        :     560 bytes*
            Reads     :     125 [3.94e+01 ~ 39.4%]
            Writes    :      77 [9.08e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel088(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel088(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)) [8] ./MPI_OpenMP/opensbliblock00Kernel088_cpu_kernel.cpp(12,30)
  -> INLINE: (148,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (149,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (150,98) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (151,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (152,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (153,98) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (154,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (155,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (156,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (157,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (159,16) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (159,32) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (161,18) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (161,36) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (163,18) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (163,36) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (165,18) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (165,36) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (167,17) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (167,34) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel088_cpu_kernel.cpp(134,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel088_cpu_kernel.cpp(135,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel088_cpu_kernel.cpp(147,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel088_cpu_kernel.cpp(147,7)
   <Remainder loop for vectorization>
      remark #15335: remainder loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel088_cpu_kernel.cpp(33,24):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel088_cpu_kernel.cpp(33,30):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel088_cpu_kernel.cpp(33,36):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel088_cpu_kernel.cpp(33,42):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel088_cpu_kernel.cpp(33,48):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel088_cpu_kernel.cpp(33,54):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel088_cpu_kernel.cpp(33,60):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel088_cpu_kernel.cpp(33,66):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel088_cpu_kernel.cpp(33,72):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel088_cpu_kernel.cpp(33,78):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel088_cpu_kernel.cpp(12,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel088PKcP14ops_block_coreiPi7ops_argS4_S4_S4_S4_S4_S4_S4_S4_S4_] ./MPI_OpenMP/opensbliblock00Kernel088_cpu_kernel.cpp:12

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   34[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm19]
        
    Routine temporaries
        Total         :     678
            Global    :     144
            Local     :     534
        Regenerable   :     191
        Spilled       :      76
        
    Routine stack
        Variables     :     836 bytes*
            Reads     :      30 [2.70e-03 ~ 0.0%]
            Writes    :      65 [9.36e-03 ~ 0.0%]
        Spills        :     648 bytes*
            Reads     :     130 [5.14e-02 ~ 0.1%]
            Writes    :      87 [3.26e-02 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel003(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel003(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg)) [9] ./MPI_OpenMP/opensbliblock00Kernel003_cpu_kernel.cpp(10,44)
  -> INLINE: (104,98) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (105,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (106,91) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (108,9) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (108,27) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (108,41) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel003_cpu_kernel.cpp(90,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel003_cpu_kernel.cpp(91,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel003_cpu_kernel.cpp(103,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel003_cpu_kernel.cpp(103,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel003_cpu_kernel.cpp(24,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel003_cpu_kernel.cpp(24,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel003_cpu_kernel.cpp(24,35):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel003_cpu_kernel.cpp(10,44):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel003PKcP14ops_block_coreiPi7ops_argS4_S4_] ./MPI_OpenMP/opensbliblock00Kernel003_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   24[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm8 k1]
        
    Routine temporaries
        Total         :     362
            Global    :      81
            Local     :     281
        Regenerable   :     115
        Spilled       :      26
        
    Routine stack
        Variables     :     332 bytes*
            Reads     :      16 [1.04e-03 ~ 0.0%]
            Writes    :      23 [3.75e-03 ~ 0.0%]
        Spills        :     248 bytes*
            Reads     :      54 [2.03e-02 ~ 0.0%]
            Writes    :      36 [1.32e-02 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel024(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel024(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg)) [10] ./MPI_OpenMP/opensbliblock00Kernel024_cpu_kernel.cpp(10,44)
  -> INLINE: (104,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (105,98) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (106,91) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (108,9) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (108,27) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (108,41) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel024_cpu_kernel.cpp(90,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel024_cpu_kernel.cpp(91,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel024_cpu_kernel.cpp(103,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel024_cpu_kernel.cpp(103,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel024_cpu_kernel.cpp(24,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel024_cpu_kernel.cpp(24,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel024_cpu_kernel.cpp(24,35):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel024_cpu_kernel.cpp(10,44):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel024PKcP14ops_block_coreiPi7ops_argS4_S4_] ./MPI_OpenMP/opensbliblock00Kernel024_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   24[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm8 k1]
        
    Routine temporaries
        Total         :     362
            Global    :      81
            Local     :     281
        Regenerable   :     115
        Spilled       :      26
        
    Routine stack
        Variables     :     332 bytes*
            Reads     :      16 [1.04e-03 ~ 0.0%]
            Writes    :      23 [3.75e-03 ~ 0.0%]
        Spills        :     248 bytes*
            Reads     :      54 [2.03e-02 ~ 0.0%]
            Writes    :      36 [1.32e-02 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel038(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel038(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg)) [11] ./MPI_OpenMP/opensbliblock00Kernel038_cpu_kernel.cpp(10,44)
  -> INLINE: (104,98) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (105,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (106,91) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (108,9) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (108,27) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (108,41) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel038_cpu_kernel.cpp(90,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel038_cpu_kernel.cpp(91,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel038_cpu_kernel.cpp(103,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel038_cpu_kernel.cpp(103,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel038_cpu_kernel.cpp(24,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel038_cpu_kernel.cpp(24,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel038_cpu_kernel.cpp(24,35):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel038_cpu_kernel.cpp(10,44):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel038PKcP14ops_block_coreiPi7ops_argS4_S4_] ./MPI_OpenMP/opensbliblock00Kernel038_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   24[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm8 k1]
        
    Routine temporaries
        Total         :     362
            Global    :      81
            Local     :     281
        Regenerable   :     115
        Spilled       :      26
        
    Routine stack
        Variables     :     332 bytes*
            Reads     :      16 [1.04e-03 ~ 0.0%]
            Writes    :      23 [3.75e-03 ~ 0.0%]
        Spills        :     248 bytes*
            Reads     :      54 [2.03e-02 ~ 0.0%]
            Writes    :      36 [1.32e-02 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel009(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel009(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)) [12] ./MPI_OpenMP/opensbliblock00Kernel009_cpu_kernel.cpp(11,30)
  -> INLINE: (123,97) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (124,97) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (125,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (126,98) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (127,97) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (128,90) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (130,9) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (130,38) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (131,17) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (131,25) std::pow<double, int>(double, int)
     {{ Inlining of routines from system headers is omitted. Use -qopt-report=3 to view full report. }}
  -> INLINE: (131,34) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (132,17) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (132,25) std::pow<double, int>(double, int)
     {{ Inlining of routines from system headers is omitted. Use -qopt-report=3 to view full report. }}
  -> INLINE: (132,34) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (133,17) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (133,25) std::pow<double, int>(double, int)
     {{ Inlining of routines from system headers is omitted. Use -qopt-report=3 to view full report. }}
  -> INLINE: (133,34) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel009_cpu_kernel.cpp(109,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel009_cpu_kernel.cpp(110,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel009_cpu_kernel.cpp(122,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel009_cpu_kernel.cpp(122,7)
   <Remainder loop for vectorization>
      remark #15335: remainder loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel009_cpu_kernel.cpp(28,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel009_cpu_kernel.cpp(28,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel009_cpu_kernel.cpp(28,35):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel009_cpu_kernel.cpp(28,41):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel009_cpu_kernel.cpp(28,47):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel009_cpu_kernel.cpp(28,53):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel009_cpu_kernel.cpp(11,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel009PKcP14ops_block_coreiPi7ops_argS4_S4_S4_S4_S4_] ./MPI_OpenMP/opensbliblock00Kernel009_cpu_kernel.cpp:11

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   26[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm11]
        
    Routine temporaries
        Total         :     502
            Global    :     105
            Local     :     397
        Regenerable   :     144
        Spilled       :      45
        
    Routine stack
        Variables     :     548 bytes*
            Reads     :      22 [1.35e-03 ~ 0.0%]
            Writes    :      41 [4.74e-03 ~ 0.0%]
        Spills        :     400 bytes*
            Reads     :      82 [2.41e-02 ~ 0.0%]
            Writes    :      55 [1.57e-02 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel079(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel079(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg)) [13] ./MPI_OpenMP/opensbliblock00Kernel079_cpu_kernel.cpp(10,44)
  -> INLINE: (104,96) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (105,98) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (106,90) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (108,8) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (108,18) std::pow<double, int>(double, int)
     {{ Inlining of routines from system headers is omitted. Use -qopt-report=3 to view full report. }}
  -> INLINE: (108,40) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (108,54) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel079_cpu_kernel.cpp(90,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel079_cpu_kernel.cpp(91,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel079_cpu_kernel.cpp(103,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel079_cpu_kernel.cpp(103,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel079_cpu_kernel.cpp(24,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel079_cpu_kernel.cpp(24,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel079_cpu_kernel.cpp(24,35):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel079_cpu_kernel.cpp(10,44):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel079PKcP14ops_block_coreiPi7ops_argS4_S4_] ./MPI_OpenMP/opensbliblock00Kernel079_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   40[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm24 k1]
        
    Routine temporaries
        Total         :     382
            Global    :      81
            Local     :     301
        Regenerable   :     115
        Spilled       :      26
        
    Routine stack
        Variables     :     332 bytes*
            Reads     :      16 [5.78e-04 ~ 0.0%]
            Writes    :      23 [2.08e-03 ~ 0.0%]
        Spills        :     248 bytes*
            Reads     :      54 [1.13e-02 ~ 0.0%]
            Writes    :      36 [7.35e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel000(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel000(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)) [14] ./MPI_OpenMP/opensbliblock00Kernel000_cpu_kernel.cpp(13,17)
  -> INLINE: (167,96) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (168,97) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (169,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (170,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (171,98) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (172,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (173,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (174,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (175,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (176,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (177,95) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (178,95) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (179,95) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (181,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (181,25) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (181,38) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (183,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (183,29) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (183,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (185,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (185,29) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (185,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (187,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (187,28) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (187,41) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (189,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (189,27) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (189,40) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (191,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (191,29) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (191,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel000_cpu_kernel.cpp(153,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel000_cpu_kernel.cpp(154,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel000_cpu_kernel.cpp(166,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel000_cpu_kernel.cpp(166,7)
   <Remainder loop for vectorization>
      remark #15335: remainder loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel000_cpu_kernel.cpp(37,24):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel000_cpu_kernel.cpp(37,30):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel000_cpu_kernel.cpp(37,36):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel000_cpu_kernel.cpp(37,42):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel000_cpu_kernel.cpp(37,48):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel000_cpu_kernel.cpp(37,54):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel000_cpu_kernel.cpp(37,60):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel000_cpu_kernel.cpp(37,66):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel000_cpu_kernel.cpp(37,72):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel000_cpu_kernel.cpp(37,78):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel000_cpu_kernel.cpp(37,84):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel000_cpu_kernel.cpp(37,91):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel000_cpu_kernel.cpp(37,98):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel000_cpu_kernel.cpp(13,17):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel000PKcP14ops_block_coreiPi7ops_argS4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_] ./MPI_OpenMP/opensbliblock00Kernel000_cpu_kernel.cpp:13

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   40[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm25]
        
    Routine temporaries
        Total         :     845
            Global    :     175
            Local     :     670
        Regenerable   :     223
        Spilled       :     105
        
    Routine stack
        Variables     :    1052 bytes*
            Reads     :      36 [1.43e-03 ~ 0.0%]
            Writes    :      83 [4.92e-03 ~ 0.0%]
        Spills        :     880 bytes*
            Reads     :     176 [8.84e+00 ~ 8.8%]
            Writes    :     120 [1.84e-02 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel002(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel002(const char *, ops_block, int, int *, ops_arg, ops_arg)) [15] ./MPI_OpenMP/opensbliblock00Kernel002_cpu_kernel.cpp(10,30)
  -> INLINE: (98,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,92) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,41) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,66) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,19) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,43) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel002_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel002_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel002_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel002_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel002_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel002_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel002_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel002PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel002_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     328
            Global    :      66
            Local     :     262
        Regenerable   :     104
        Spilled       :      22
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.57e-04 ~ 0.0%]
            Writes    :      17 [1.31e-03 ~ 0.0%]
        Spills        :     208 bytes*
            Reads     :      48 [5.67e+00 ~ 5.7%]
            Writes    :      34 [5.96e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel004(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel004(const char *, ops_block, int, int *, ops_arg, ops_arg)) [16] ./MPI_OpenMP/opensbliblock00Kernel004_cpu_kernel.cpp(10,30)
  -> INLINE: (98,97) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,92) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,38) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,60) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,16) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,37) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel004_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel004_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel004_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel004_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel004_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel004_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel004_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel004PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel004_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     328
            Global    :      66
            Local     :     262
        Regenerable   :     104
        Spilled       :      22
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.57e-04 ~ 0.0%]
            Writes    :      17 [1.31e-03 ~ 0.0%]
        Spills        :     208 bytes*
            Reads     :      48 [5.67e+00 ~ 5.7%]
            Writes    :      34 [5.96e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel006(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel006(const char *, ops_block, int, int *, ops_arg, ops_arg)) [17] ./MPI_OpenMP/opensbliblock00Kernel006_cpu_kernel.cpp(10,30)
  -> INLINE: (98,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,92) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,41) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,63) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,20) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,41) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel006_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel006_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel006_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel006_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel006_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel006_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel006_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel006PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel006_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     323
            Global    :      66
            Local     :     257
        Regenerable   :     104
        Spilled       :      23
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.94e-04 ~ 0.0%]
            Writes    :      17 [1.45e-03 ~ 0.0%]
        Spills        :     216 bytes*
            Reads     :      49 [6.26e+00 ~ 6.3%]
            Writes    :      35 [6.96e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel008(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel008(const char *, ops_block, int, int *, ops_arg, ops_arg)) [18] ./MPI_OpenMP/opensbliblock00Kernel008_cpu_kernel.cpp(10,30)
  -> INLINE: (98,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,92) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,65) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,21) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,43) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel008_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel008_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel008_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel008_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel008_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel008_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel008_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel008PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel008_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     323
            Global    :      66
            Local     :     257
        Regenerable   :     104
        Spilled       :      22
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.94e-04 ~ 0.0%]
            Writes    :      17 [1.45e-03 ~ 0.0%]
        Spills        :     208 bytes*
            Reads     :      48 [6.26e+00 ~ 6.3%]
            Writes    :      34 [6.58e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel010(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel010(const char *, ops_block, int, int *, ops_arg, ops_arg)) [19] ./MPI_OpenMP/opensbliblock00Kernel010_cpu_kernel.cpp(10,30)
  -> INLINE: (98,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,92) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,40) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,64) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,20) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel010_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel010_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel010_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel010_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel010_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel010_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel010_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel010PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel010_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     328
            Global    :      66
            Local     :     262
        Regenerable   :     104
        Spilled       :      23
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.57e-04 ~ 0.0%]
            Writes    :      17 [1.31e-03 ~ 0.0%]
        Spills        :     216 bytes*
            Reads     :      49 [5.67e+00 ~ 5.7%]
            Writes    :      35 [6.31e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel011(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel011(const char *, ops_block, int, int *, ops_arg, ops_arg)) [20] ./MPI_OpenMP/opensbliblock00Kernel011_cpu_kernel.cpp(10,30)
  -> INLINE: (98,96) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,92) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,37) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,58) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,15) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,35) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel011_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel011_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel011_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel011_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel011_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel011_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel011_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel011PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel011_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     328
            Global    :      66
            Local     :     262
        Regenerable   :     104
        Spilled       :      22
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.57e-04 ~ 0.0%]
            Writes    :      17 [1.31e-03 ~ 0.0%]
        Spills        :     208 bytes*
            Reads     :      48 [5.67e+00 ~ 5.7%]
            Writes    :      34 [5.96e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel012(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel012(const char *, ops_block, int, int *, ops_arg, ops_arg)) [21] ./MPI_OpenMP/opensbliblock00Kernel012_cpu_kernel.cpp(10,30)
  -> INLINE: (98,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,92) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,40) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,63) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,18) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel012_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel012_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel012_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel012_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel012_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel012_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel012_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel012PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel012_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     328
            Global    :      66
            Local     :     262
        Regenerable   :     104
        Spilled       :      22
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.57e-04 ~ 0.0%]
            Writes    :      17 [1.31e-03 ~ 0.0%]
        Spills        :     208 bytes*
            Reads     :      48 [5.67e+00 ~ 5.7%]
            Writes    :      34 [5.96e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel014(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel014(const char *, ops_block, int, int *, ops_arg, ops_arg)) [22] ./MPI_OpenMP/opensbliblock00Kernel014_cpu_kernel.cpp(10,30)
  -> INLINE: (98,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,92) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,41) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,66) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,19) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,43) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel014_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel014_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel014_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel014_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel014_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel014_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel014_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel014PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel014_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     328
            Global    :      66
            Local     :     262
        Regenerable   :     104
        Spilled       :      22
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.57e-04 ~ 0.0%]
            Writes    :      17 [1.31e-03 ~ 0.0%]
        Spills        :     208 bytes*
            Reads     :      48 [5.67e+00 ~ 5.7%]
            Writes    :      34 [5.96e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel015(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel015(const char *, ops_block, int, int *, ops_arg, ops_arg)) [23] ./MPI_OpenMP/opensbliblock00Kernel015_cpu_kernel.cpp(10,30)
  -> INLINE: (98,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,92) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,41) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,63) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,20) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,41) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel015_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel015_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel015_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel015_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel015_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel015_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel015_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel015PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel015_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     323
            Global    :      66
            Local     :     257
        Regenerable   :     104
        Spilled       :      23
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.94e-04 ~ 0.0%]
            Writes    :      17 [1.45e-03 ~ 0.0%]
        Spills        :     216 bytes*
            Reads     :      49 [6.26e+00 ~ 6.3%]
            Writes    :      35 [6.96e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel016(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel016(const char *, ops_block, int, int *, ops_arg, ops_arg)) [24] ./MPI_OpenMP/opensbliblock00Kernel016_cpu_kernel.cpp(10,30)
  -> INLINE: (98,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,92) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,40) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,64) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,18) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,41) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel016_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel016_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel016_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel016_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel016_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel016_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel016_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel016PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel016_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     328
            Global    :      66
            Local     :     262
        Regenerable   :     104
        Spilled       :      22
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.57e-04 ~ 0.0%]
            Writes    :      17 [1.31e-03 ~ 0.0%]
        Spills        :     208 bytes*
            Reads     :      48 [5.67e+00 ~ 5.7%]
            Writes    :      34 [5.96e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel018(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel018(const char *, ops_block, int, int *, ops_arg, ops_arg)) [25] ./MPI_OpenMP/opensbliblock00Kernel018_cpu_kernel.cpp(10,30)
  -> INLINE: (98,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,41) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,64) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,18) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel018_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel018_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel018_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel018_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel018_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel018_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel018_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel018PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel018_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     328
            Global    :      66
            Local     :     262
        Regenerable   :     104
        Spilled       :      22
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.57e-04 ~ 0.0%]
            Writes    :      17 [1.31e-03 ~ 0.0%]
        Spills        :     208 bytes*
            Reads     :      48 [5.67e+00 ~ 5.7%]
            Writes    :      34 [5.96e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel019(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel019(const char *, ops_block, int, int *, ops_arg, ops_arg)) [26] ./MPI_OpenMP/opensbliblock00Kernel019_cpu_kernel.cpp(10,30)
  -> INLINE: (98,98) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,40) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,62) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,17) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,40) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel019_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel019_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel019_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel019_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel019_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel019_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel019_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel019PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel019_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     328
            Global    :      66
            Local     :     262
        Regenerable   :     104
        Spilled       :      22
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.57e-04 ~ 0.0%]
            Writes    :      17 [1.31e-03 ~ 0.0%]
        Spills        :     208 bytes*
            Reads     :      48 [5.67e+00 ~ 5.7%]
            Writes    :      34 [5.96e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel020(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel020(const char *, ops_block, int, int *, ops_arg, ops_arg)) [27] ./MPI_OpenMP/opensbliblock00Kernel020_cpu_kernel.cpp(10,30)
  -> INLINE: (98,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,41) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,64) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,18) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel020_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel020_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel020_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel020_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel020_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel020_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel020_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel020PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel020_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     328
            Global    :      66
            Local     :     262
        Regenerable   :     104
        Spilled       :      22
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.57e-04 ~ 0.0%]
            Writes    :      17 [1.31e-03 ~ 0.0%]
        Spills        :     208 bytes*
            Reads     :      48 [5.67e+00 ~ 5.7%]
            Writes    :      34 [5.96e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel021(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel021(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)) [28] ./MPI_OpenMP/opensbliblock00Kernel021_cpu_kernel.cpp(13,17)
  -> INLINE: (167,96) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (168,97) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (169,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (170,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (171,98) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (172,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (173,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (174,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (175,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (176,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (177,95) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (178,95) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (179,95) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (181,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (181,29) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (181,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (183,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (183,27) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (183,40) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (185,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (185,28) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (185,41) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (187,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (187,29) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (187,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (189,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (189,25) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (189,38) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (191,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (191,29) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (191,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel021_cpu_kernel.cpp(153,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel021_cpu_kernel.cpp(154,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel021_cpu_kernel.cpp(166,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel021_cpu_kernel.cpp(166,7)
   <Remainder loop for vectorization>
      remark #15335: remainder loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel021_cpu_kernel.cpp(37,24):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel021_cpu_kernel.cpp(37,30):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel021_cpu_kernel.cpp(37,36):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel021_cpu_kernel.cpp(37,42):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel021_cpu_kernel.cpp(37,48):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel021_cpu_kernel.cpp(37,54):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel021_cpu_kernel.cpp(37,60):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel021_cpu_kernel.cpp(37,66):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel021_cpu_kernel.cpp(37,72):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel021_cpu_kernel.cpp(37,78):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel021_cpu_kernel.cpp(37,84):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel021_cpu_kernel.cpp(37,91):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel021_cpu_kernel.cpp(37,98):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel021_cpu_kernel.cpp(13,17):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel021PKcP14ops_block_coreiPi7ops_argS4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_] ./MPI_OpenMP/opensbliblock00Kernel021_cpu_kernel.cpp:13

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   40[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm25]
        
    Routine temporaries
        Total         :     845
            Global    :     175
            Local     :     670
        Regenerable   :     223
        Spilled       :     105
        
    Routine stack
        Variables     :    1052 bytes*
            Reads     :      36 [1.43e-03 ~ 0.0%]
            Writes    :      83 [4.92e-03 ~ 0.0%]
        Spills        :     880 bytes*
            Reads     :     176 [8.84e+00 ~ 8.8%]
            Writes    :     120 [1.84e-02 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel022(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel022(const char *, ops_block, int, int *, ops_arg, ops_arg)) [29] ./MPI_OpenMP/opensbliblock00Kernel022_cpu_kernel.cpp(10,30)
  -> INLINE: (98,96) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,38) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,59) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,15) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,35) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel022_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel022_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel022_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel022_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel022_cpu_kernel.cpp(101,59):remark #34060: alignment of adjacent dense (unit-strided stencil) loads is (alignment, offset): (1, 0)
./MPI_OpenMP/opensbliblock00Kernel022_cpu_kernel.cpp(101,59):remark #34050: adjacent dense (unit-strided stencil) loads seem unprofitable to optimize.
./MPI_OpenMP/opensbliblock00Kernel022_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel022_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel022_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel022PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel022_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     322
            Global    :      64
            Local     :     258
        Regenerable   :     104
        Spilled       :      25
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.57e-04 ~ 0.0%]
            Writes    :      17 [1.31e-03 ~ 0.0%]
        Spills        :     232 bytes*
            Reads     :      47 [8.09e-03 ~ 0.0%]
            Writes    :      36 [5.63e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel023(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel023(const char *, ops_block, int, int *, ops_arg, ops_arg)) [30] ./MPI_OpenMP/opensbliblock00Kernel023_cpu_kernel.cpp(10,30)
  -> INLINE: (98,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,67) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,19) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,43) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel023_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel023_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel023_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel023_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel023_cpu_kernel.cpp(101,67):remark #34060: alignment of adjacent dense (unit-strided stencil) loads is (alignment, offset): (1, 0)
./MPI_OpenMP/opensbliblock00Kernel023_cpu_kernel.cpp(101,67):remark #34050: adjacent dense (unit-strided stencil) loads seem unprofitable to optimize.
./MPI_OpenMP/opensbliblock00Kernel023_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel023_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel023_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel023PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel023_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     322
            Global    :      64
            Local     :     258
        Regenerable   :     104
        Spilled       :      25
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.57e-04 ~ 0.0%]
            Writes    :      17 [1.31e-03 ~ 0.0%]
        Spills        :     232 bytes*
            Reads     :      47 [8.09e-03 ~ 0.0%]
            Writes    :      36 [5.63e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel025(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel025(const char *, ops_block, int, int *, ops_arg, ops_arg)) [31] ./MPI_OpenMP/opensbliblock00Kernel025_cpu_kernel.cpp(10,30)
  -> INLINE: (98,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,41) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,65) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,20) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel025_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel025_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel025_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel025_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel025_cpu_kernel.cpp(101,65):remark #34060: alignment of adjacent dense (unit-strided stencil) loads is (alignment, offset): (1, 0)
./MPI_OpenMP/opensbliblock00Kernel025_cpu_kernel.cpp(101,65):remark #34050: adjacent dense (unit-strided stencil) loads seem unprofitable to optimize.
./MPI_OpenMP/opensbliblock00Kernel025_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel025_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel025_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel025PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel025_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     322
            Global    :      64
            Local     :     258
        Regenerable   :     104
        Spilled       :      25
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.57e-04 ~ 0.0%]
            Writes    :      17 [1.31e-03 ~ 0.0%]
        Spills        :     232 bytes*
            Reads     :      47 [8.09e-03 ~ 0.0%]
            Writes    :      36 [5.63e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel026(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel026(const char *, ops_block, int, int *, ops_arg, ops_arg)) [32] ./MPI_OpenMP/opensbliblock00Kernel026_cpu_kernel.cpp(10,30)
  -> INLINE: (98,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,41) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,64) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,18) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel026_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel026_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel026_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel026_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel026_cpu_kernel.cpp(101,41):remark #34060: alignment of adjacent dense (unit-strided stencil) loads is (alignment, offset): (1, 0)
./MPI_OpenMP/opensbliblock00Kernel026_cpu_kernel.cpp(101,41):remark #34050: adjacent dense (unit-strided stencil) loads seem unprofitable to optimize.
./MPI_OpenMP/opensbliblock00Kernel026_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel026_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel026_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel026PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel026_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     322
            Global    :      64
            Local     :     258
        Regenerable   :     104
        Spilled       :      25
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.57e-04 ~ 0.0%]
            Writes    :      17 [1.31e-03 ~ 0.0%]
        Spills        :     232 bytes*
            Reads     :      47 [8.09e-03 ~ 0.0%]
            Writes    :      36 [5.63e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel027(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel027(const char *, ops_block, int, int *, ops_arg, ops_arg)) [33] ./MPI_OpenMP/opensbliblock00Kernel027_cpu_kernel.cpp(10,30)
  -> INLINE: (98,97) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,39) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,60) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,16) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,38) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel027_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel027_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel027_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel027_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel027_cpu_kernel.cpp(101,39):remark #34060: alignment of adjacent dense (unit-strided stencil) loads is (alignment, offset): (1, 0)
./MPI_OpenMP/opensbliblock00Kernel027_cpu_kernel.cpp(101,39):remark #34050: adjacent dense (unit-strided stencil) loads seem unprofitable to optimize.
./MPI_OpenMP/opensbliblock00Kernel027_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel027_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel027_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel027PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel027_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     322
            Global    :      64
            Local     :     258
        Regenerable   :     104
        Spilled       :      25
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.57e-04 ~ 0.0%]
            Writes    :      17 [1.31e-03 ~ 0.0%]
        Spills        :     232 bytes*
            Reads     :      47 [8.09e-03 ~ 0.0%]
            Writes    :      36 [5.63e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel028(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel028(const char *, ops_block, int, int *, ops_arg, ops_arg)) [34] ./MPI_OpenMP/opensbliblock00Kernel028_cpu_kernel.cpp(10,30)
  -> INLINE: (98,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,43) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,66) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,21) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,43) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel028_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel028_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel028_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel028_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel028_cpu_kernel.cpp(102,21):remark #34060: alignment of adjacent dense (unit-strided stencil) loads is (alignment, offset): (1, 0)
./MPI_OpenMP/opensbliblock00Kernel028_cpu_kernel.cpp(102,21):remark #34050: adjacent dense (unit-strided stencil) loads seem unprofitable to optimize.
./MPI_OpenMP/opensbliblock00Kernel028_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel028_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel028_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel028PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel028_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     317
            Global    :      64
            Local     :     253
        Regenerable   :     104
        Spilled       :      25
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.94e-04 ~ 0.0%]
            Writes    :      17 [1.45e-03 ~ 0.0%]
        Spills        :     232 bytes*
            Reads     :      47 [8.93e-03 ~ 0.0%]
            Writes    :      36 [6.22e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel029(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel029(const char *, ops_block, int, int *, ops_arg, ops_arg)) [35] ./MPI_OpenMP/opensbliblock00Kernel029_cpu_kernel.cpp(10,30)
  -> INLINE: (98,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,64) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,20) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,41) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel029_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel029_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel029_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel029_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel029_cpu_kernel.cpp(101,64):remark #34060: alignment of adjacent dense (unit-strided stencil) loads is (alignment, offset): (1, 0)
./MPI_OpenMP/opensbliblock00Kernel029_cpu_kernel.cpp(101,64):remark #34050: adjacent dense (unit-strided stencil) loads seem unprofitable to optimize.
./MPI_OpenMP/opensbliblock00Kernel029_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel029_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel029_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel029PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel029_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     317
            Global    :      64
            Local     :     253
        Regenerable   :     104
        Spilled       :      25
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.94e-04 ~ 0.0%]
            Writes    :      17 [1.45e-03 ~ 0.0%]
        Spills        :     232 bytes*
            Reads     :      47 [8.93e-03 ~ 0.0%]
            Writes    :      36 [6.22e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel030(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel030(const char *, ops_block, int, int *, ops_arg, ops_arg)) [36] ./MPI_OpenMP/opensbliblock00Kernel030_cpu_kernel.cpp(10,30)
  -> INLINE: (98,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,64) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,20) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,41) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel030_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel030_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel030_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel030_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel030_cpu_kernel.cpp(101,64):remark #34060: alignment of adjacent dense (unit-strided stencil) loads is (alignment, offset): (1, 0)
./MPI_OpenMP/opensbliblock00Kernel030_cpu_kernel.cpp(101,64):remark #34050: adjacent dense (unit-strided stencil) loads seem unprofitable to optimize.
./MPI_OpenMP/opensbliblock00Kernel030_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel030_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel030_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel030PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel030_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     317
            Global    :      64
            Local     :     253
        Regenerable   :     104
        Spilled       :      25
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.94e-04 ~ 0.0%]
            Writes    :      17 [1.45e-03 ~ 0.0%]
        Spills        :     232 bytes*
            Reads     :      47 [8.93e-03 ~ 0.0%]
            Writes    :      36 [6.22e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel031(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel031(const char *, ops_block, int, int *, ops_arg, ops_arg)) [37] ./MPI_OpenMP/opensbliblock00Kernel031_cpu_kernel.cpp(10,30)
  -> INLINE: (98,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,67) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,19) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,43) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel031_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel031_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel031_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel031_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel031_cpu_kernel.cpp(101,67):remark #34060: alignment of adjacent dense (unit-strided stencil) loads is (alignment, offset): (1, 0)
./MPI_OpenMP/opensbliblock00Kernel031_cpu_kernel.cpp(101,67):remark #34050: adjacent dense (unit-strided stencil) loads seem unprofitable to optimize.
./MPI_OpenMP/opensbliblock00Kernel031_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel031_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel031_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel031PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel031_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     322
            Global    :      64
            Local     :     258
        Regenerable   :     104
        Spilled       :      25
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.57e-04 ~ 0.0%]
            Writes    :      17 [1.31e-03 ~ 0.0%]
        Spills        :     232 bytes*
            Reads     :      47 [8.09e-03 ~ 0.0%]
            Writes    :      36 [5.63e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel032(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel032(const char *, ops_block, int, int *, ops_arg, ops_arg)) [38] ./MPI_OpenMP/opensbliblock00Kernel032_cpu_kernel.cpp(10,30)
  -> INLINE: (98,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,41) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,65) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,18) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,41) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel032_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel032_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel032_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel032_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel032_cpu_kernel.cpp(101,65):remark #34060: alignment of adjacent dense (unit-strided stencil) loads is (alignment, offset): (1, 0)
./MPI_OpenMP/opensbliblock00Kernel032_cpu_kernel.cpp(101,65):remark #34050: adjacent dense (unit-strided stencil) loads seem unprofitable to optimize.
./MPI_OpenMP/opensbliblock00Kernel032_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel032_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel032_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel032PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel032_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     322
            Global    :      64
            Local     :     258
        Regenerable   :     104
        Spilled       :      25
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.57e-04 ~ 0.0%]
            Writes    :      17 [1.31e-03 ~ 0.0%]
        Spills        :     232 bytes*
            Reads     :      47 [8.09e-03 ~ 0.0%]
            Writes    :      36 [5.63e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel033(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel033(const char *, ops_block, int, int *, ops_arg, ops_arg)) [39] ./MPI_OpenMP/opensbliblock00Kernel033_cpu_kernel.cpp(10,30)
  -> INLINE: (98,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,41) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,64) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,18) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel033_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel033_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel033_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel033_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel033_cpu_kernel.cpp(101,41):remark #34060: alignment of adjacent dense (unit-strided stencil) loads is (alignment, offset): (1, 0)
./MPI_OpenMP/opensbliblock00Kernel033_cpu_kernel.cpp(101,41):remark #34050: adjacent dense (unit-strided stencil) loads seem unprofitable to optimize.
./MPI_OpenMP/opensbliblock00Kernel033_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel033_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel033_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel033PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel033_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     322
            Global    :      64
            Local     :     258
        Regenerable   :     104
        Spilled       :      25
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.57e-04 ~ 0.0%]
            Writes    :      17 [1.31e-03 ~ 0.0%]
        Spills        :     232 bytes*
            Reads     :      47 [8.09e-03 ~ 0.0%]
            Writes    :      36 [5.63e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel034(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel034(const char *, ops_block, int, int *, ops_arg, ops_arg)) [40] ./MPI_OpenMP/opensbliblock00Kernel034_cpu_kernel.cpp(10,30)
  -> INLINE: (98,98) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,40) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,62) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,17) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,40) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel034_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel034_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel034_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel034_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel034_cpu_kernel.cpp(101,40):remark #34060: alignment of adjacent dense (unit-strided stencil) loads is (alignment, offset): (1, 0)
./MPI_OpenMP/opensbliblock00Kernel034_cpu_kernel.cpp(101,40):remark #34050: adjacent dense (unit-strided stencil) loads seem unprofitable to optimize.
./MPI_OpenMP/opensbliblock00Kernel034_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel034_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel034_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel034PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel034_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     322
            Global    :      64
            Local     :     258
        Regenerable   :     104
        Spilled       :      25
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.57e-04 ~ 0.0%]
            Writes    :      17 [1.31e-03 ~ 0.0%]
        Spills        :     232 bytes*
            Reads     :      47 [8.09e-03 ~ 0.0%]
            Writes    :      36 [5.63e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel035(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel035(const char *, ops_block, int, int *, ops_arg, ops_arg)) [41] ./MPI_OpenMP/opensbliblock00Kernel035_cpu_kernel.cpp(10,30)
  -> INLINE: (98,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,41) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,64) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,18) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel035_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel035_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel035_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel035_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel035_cpu_kernel.cpp(101,41):remark #34060: alignment of adjacent dense (unit-strided stencil) loads is (alignment, offset): (1, 0)
./MPI_OpenMP/opensbliblock00Kernel035_cpu_kernel.cpp(101,41):remark #34050: adjacent dense (unit-strided stencil) loads seem unprofitable to optimize.
./MPI_OpenMP/opensbliblock00Kernel035_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel035_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel035_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel035PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel035_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     322
            Global    :      64
            Local     :     258
        Regenerable   :     104
        Spilled       :      25
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.57e-04 ~ 0.0%]
            Writes    :      17 [1.31e-03 ~ 0.0%]
        Spills        :     232 bytes*
            Reads     :      47 [8.09e-03 ~ 0.0%]
            Writes    :      36 [5.63e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel036(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel036(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)) [42] ./MPI_OpenMP/opensbliblock00Kernel036_cpu_kernel.cpp(13,17)
  -> INLINE: (167,96) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (168,97) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (169,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (170,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (171,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (172,98) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (173,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (174,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (175,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (176,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (177,95) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (178,95) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (179,95) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (181,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (181,28) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (181,41) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (183,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (183,25) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (183,38) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (185,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (185,27) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (185,40) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (187,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (187,29) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (187,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (189,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (189,29) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (189,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (191,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (191,29) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (191,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel036_cpu_kernel.cpp(153,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel036_cpu_kernel.cpp(154,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel036_cpu_kernel.cpp(166,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel036_cpu_kernel.cpp(166,7)
   <Remainder loop for vectorization>
      remark #15335: remainder loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel036_cpu_kernel.cpp(37,24):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel036_cpu_kernel.cpp(37,30):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel036_cpu_kernel.cpp(37,36):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel036_cpu_kernel.cpp(37,42):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel036_cpu_kernel.cpp(37,48):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel036_cpu_kernel.cpp(37,54):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel036_cpu_kernel.cpp(37,60):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel036_cpu_kernel.cpp(37,66):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel036_cpu_kernel.cpp(37,72):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel036_cpu_kernel.cpp(37,78):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel036_cpu_kernel.cpp(37,84):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel036_cpu_kernel.cpp(37,91):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel036_cpu_kernel.cpp(37,98):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel036_cpu_kernel.cpp(13,17):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel036PKcP14ops_block_coreiPi7ops_argS4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_] ./MPI_OpenMP/opensbliblock00Kernel036_cpu_kernel.cpp:13

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   40[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm25]
        
    Routine temporaries
        Total         :     845
            Global    :     175
            Local     :     670
        Regenerable   :     223
        Spilled       :     105
        
    Routine stack
        Variables     :    1052 bytes*
            Reads     :      36 [1.43e-03 ~ 0.0%]
            Writes    :      83 [4.92e-03 ~ 0.0%]
        Spills        :     880 bytes*
            Reads     :     176 [8.84e+00 ~ 8.8%]
            Writes    :     120 [1.84e-02 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel037(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel037(const char *, ops_block, int, int *, ops_arg, ops_arg)) [43] ./MPI_OpenMP/opensbliblock00Kernel037_cpu_kernel.cpp(10,30)
  -> INLINE: (98,96) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,38) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,57) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,17) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,38) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel037_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel037_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel037_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel037_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel037_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel037_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel037_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel037PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel037_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     330
            Global    :      66
            Local     :     264
        Regenerable   :     104
        Spilled       :      24
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.57e-04 ~ 0.0%]
            Writes    :      17 [1.31e-03 ~ 0.0%]
        Spills        :     216 bytes*
            Reads     :      47 [5.67e+00 ~ 5.7%]
            Writes    :      34 [5.97e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel039(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel039(const char *, ops_block, int, int *, ops_arg, ops_arg)) [44] ./MPI_OpenMP/opensbliblock00Kernel039_cpu_kernel.cpp(10,30)
  -> INLINE: (98,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,41) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,65) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,18) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,41) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel039_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel039_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel039_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel039_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel039_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel039_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel039_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel039PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel039_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     330
            Global    :      66
            Local     :     264
        Regenerable   :     104
        Spilled       :      24
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.57e-04 ~ 0.0%]
            Writes    :      17 [1.31e-03 ~ 0.0%]
        Spills        :     216 bytes*
            Reads     :      47 [5.67e+00 ~ 5.7%]
            Writes    :      34 [5.97e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel040(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel040(const char *, ops_block, int, int *, ops_arg, ops_arg)) [45] ./MPI_OpenMP/opensbliblock00Kernel040_cpu_kernel.cpp(10,30)
  -> INLINE: (98,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,63) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,18) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel040_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel040_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel040_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel040_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel040_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel040_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel040_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel040PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel040_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     325
            Global    :      66
            Local     :     259
        Regenerable   :     104
        Spilled       :      23
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.94e-04 ~ 0.0%]
            Writes    :      17 [1.45e-03 ~ 0.0%]
        Spills        :     208 bytes*
            Reads     :      46 [6.26e+00 ~ 6.3%]
            Writes    :      33 [6.21e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel041(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel041(const char *, ops_block, int, int *, ops_arg, ops_arg)) [46] ./MPI_OpenMP/opensbliblock00Kernel041_cpu_kernel.cpp(10,30)
  -> INLINE: (98,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,67) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,19) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,43) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel041_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel041_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel041_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel041_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel041_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel041_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel041_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel041PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel041_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     330
            Global    :      66
            Local     :     264
        Regenerable   :     104
        Spilled       :      24
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.57e-04 ~ 0.0%]
            Writes    :      17 [1.31e-03 ~ 0.0%]
        Spills        :     216 bytes*
            Reads     :      47 [5.67e+00 ~ 5.7%]
            Writes    :      34 [5.97e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel042(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel042(const char *, ops_block, int, int *, ops_arg, ops_arg)) [47] ./MPI_OpenMP/opensbliblock00Kernel042_cpu_kernel.cpp(10,30)
  -> INLINE: (98,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,63) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,20) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel042_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel042_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel042_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel042_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel042_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel042_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel042_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel042PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel042_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     325
            Global    :      66
            Local     :     259
        Regenerable   :     104
        Spilled       :      23
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.94e-04 ~ 0.0%]
            Writes    :      17 [1.45e-03 ~ 0.0%]
        Spills        :     208 bytes*
            Reads     :      46 [6.26e+00 ~ 6.3%]
            Writes    :      33 [6.21e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel043(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel043(const char *, ops_block, int, int *, ops_arg, ops_arg)) [48] ./MPI_OpenMP/opensbliblock00Kernel043_cpu_kernel.cpp(10,30)
  -> INLINE: (98,97) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,39) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,61) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,18) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,38) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel043_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel043_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel043_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel043_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel043_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel043_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel043_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel043PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel043_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     330
            Global    :      66
            Local     :     264
        Regenerable   :     104
        Spilled       :      24
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.57e-04 ~ 0.0%]
            Writes    :      17 [1.31e-03 ~ 0.0%]
        Spills        :     216 bytes*
            Reads     :      47 [5.67e+00 ~ 5.7%]
            Writes    :      34 [5.97e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel044(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel044(const char *, ops_block, int, int *, ops_arg, ops_arg)) [49] ./MPI_OpenMP/opensbliblock00Kernel044_cpu_kernel.cpp(10,30)
  -> INLINE: (98,98) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,40) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,62) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,19) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,39) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel044_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel044_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel044_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel044_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel044_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel044_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel044_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel044PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel044_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     330
            Global    :      66
            Local     :     264
        Regenerable   :     104
        Spilled       :      23
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.57e-04 ~ 0.0%]
            Writes    :      17 [1.31e-03 ~ 0.0%]
        Spills        :     208 bytes*
            Reads     :      46 [5.67e+00 ~ 5.7%]
            Writes    :      33 [5.62e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel045(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel045(const char *, ops_block, int, int *, ops_arg, ops_arg)) [50] ./MPI_OpenMP/opensbliblock00Kernel045_cpu_kernel.cpp(10,30)
  -> INLINE: (98,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,65) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,18) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,39) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel045_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel045_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel045_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel045_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel045_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel045_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel045_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel045PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel045_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     325
            Global    :      66
            Local     :     259
        Regenerable   :     104
        Spilled       :      23
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.94e-04 ~ 0.0%]
            Writes    :      17 [1.45e-03 ~ 0.0%]
        Spills        :     208 bytes*
            Reads     :      46 [6.26e+00 ~ 6.3%]
            Writes    :      33 [6.21e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel046(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel046(const char *, ops_block, int, int *, ops_arg, ops_arg)) [51] ./MPI_OpenMP/opensbliblock00Kernel046_cpu_kernel.cpp(10,30)
  -> INLINE: (98,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,41) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,63) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,20) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,44) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel046_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel046_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel046_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel046_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel046_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel046_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel046_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel046PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel046_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     330
            Global    :      66
            Local     :     264
        Regenerable   :     104
        Spilled       :      24
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.57e-04 ~ 0.0%]
            Writes    :      17 [1.31e-03 ~ 0.0%]
        Spills        :     216 bytes*
            Reads     :      47 [5.67e+00 ~ 5.7%]
            Writes    :      34 [5.97e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel047(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel047(const char *, ops_block, int, int *, ops_arg, ops_arg)) [52] ./MPI_OpenMP/opensbliblock00Kernel047_cpu_kernel.cpp(10,30)
  -> INLINE: (98,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,41) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,64) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,20) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel047_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel047_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel047_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel047_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel047_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel047_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel047_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel047PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel047_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     330
            Global    :      66
            Local     :     264
        Regenerable   :     104
        Spilled       :      23
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.57e-04 ~ 0.0%]
            Writes    :      17 [1.31e-03 ~ 0.0%]
        Spills        :     208 bytes*
            Reads     :      46 [5.67e+00 ~ 5.7%]
            Writes    :      33 [5.62e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel048(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel048(const char *, ops_block, int, int *, ops_arg, ops_arg)) [53] ./MPI_OpenMP/opensbliblock00Kernel048_cpu_kernel.cpp(10,30)
  -> INLINE: (98,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,43) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,65) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,19) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,43) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel048_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel048_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel048_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel048_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel048_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel048_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel048_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel048PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel048_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     325
            Global    :      66
            Local     :     259
        Regenerable   :     104
        Spilled       :      23
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.94e-04 ~ 0.0%]
            Writes    :      17 [1.45e-03 ~ 0.0%]
        Spills        :     208 bytes*
            Reads     :      46 [6.26e+00 ~ 6.3%]
            Writes    :      33 [6.21e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel049(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel049(const char *, ops_block, int, int *, ops_arg, ops_arg)) [54] ./MPI_OpenMP/opensbliblock00Kernel049_cpu_kernel.cpp(10,30)
  -> INLINE: (98,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,43) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,66) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,21) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,43) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel049_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel049_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel049_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel049_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel049_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel049_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel049_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel049PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel049_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     325
            Global    :      66
            Local     :     259
        Regenerable   :     104
        Spilled       :      24
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.94e-04 ~ 0.0%]
            Writes    :      17 [1.45e-03 ~ 0.0%]
        Spills        :     216 bytes*
            Reads     :      47 [6.26e+00 ~ 6.3%]
            Writes    :      34 [6.60e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel050(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel050(const char *, ops_block, int, int *, ops_arg, ops_arg)) [55] ./MPI_OpenMP/opensbliblock00Kernel050_cpu_kernel.cpp(10,30)
  -> INLINE: (98,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,63) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,18) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel050_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel050_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel050_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel050_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel050_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel050_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel050_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel050PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel050_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   25[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm9 k1]
        
    Routine temporaries
        Total         :     325
            Global    :      66
            Local     :     259
        Regenerable   :     104
        Spilled       :      23
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.94e-04 ~ 0.0%]
            Writes    :      17 [1.45e-03 ~ 0.0%]
        Spills        :     208 bytes*
            Reads     :      46 [6.26e+00 ~ 6.3%]
            Writes    :      33 [6.21e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel051(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel051(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)) [56] ./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(22,62)
  -> INLINE: (410,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (411,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (412,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (413,98) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (414,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (415,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (416,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (417,97) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (418,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (419,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (420,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (421,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (422,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (423,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (424,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (425,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (426,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (427,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (428,102) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (429,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (430,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (431,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (432,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (433,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (434,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (435,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (436,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (437,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (438,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (439,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (440,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (441,102) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (442,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (443,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (444,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (445,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (446,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (447,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (448,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (449,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (450,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (451,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (452,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (453,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (454,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (455,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (456,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (457,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (458,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (459,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (460,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (461,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (463,17) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (463,40) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (463,56) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (464,14) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (464,29) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (464,48) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (464,63) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (465,16) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (465,31) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (465,50) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (465,65) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (466,18) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (466,39) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (466,60) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (468,17) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (468,40) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (468,56) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (469,14) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (469,31) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (469,50) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (469,65) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (470,16) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (470,30) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (470,49) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (470,64) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (471,14) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (471,35) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (471,56) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (472,17) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (474,17) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (474,40) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (474,56) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (475,14) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (475,31) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (475,50) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (475,65) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (476,16) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (476,30) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (476,49) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (476,64) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (477,18) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (477,39) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (477,60) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (478,13) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (480,17) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (480,40) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (480,56) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (481,14) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (481,31) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (481,50) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (481,65) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (482,16) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (482,30) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (482,49) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (482,64) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (483,18) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (483,35) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (483,56) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (484,17) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (486,17) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (486,40) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (486,56) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (487,14) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (487,30) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (487,49) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (487,64) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (488,16) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (488,30) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (488,49) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (488,64) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (489,18) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (489,35) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (489,56) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (490,14) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (490,30) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (490,50) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(396,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(397,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(409,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(409,7)
   <Remainder loop for vectorization>
      remark #15335: remainder loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,24):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,30):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,36):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,42):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,48):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,54):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,60):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,66):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,72):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,78):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,84):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,91):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,98):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,105):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,112):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,119):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,126):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,133):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,140):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,147):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,154):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,161):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,168):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,175):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,182):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,189):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,196):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,203):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,210):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,217):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,224):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,231):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,238):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,245):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,252):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,259):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,266):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,273):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,280):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,287):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,294):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,301):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,308):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,315):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,322):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,329):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,336):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,343):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,350):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,357):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,364):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(85,371):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp(22,62):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel051PKcP14ops_block_coreiPi7ops_argS4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_] ./MPI_OpenMP/opensbliblock00Kernel051_cpu_kernel.cpp:22

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   46[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm31]
        
    Routine temporaries
        Total         :    2775
            Global    :     583
            Local     :    2192
        Regenerable   :     611
        Spilled       :     434
        
    Routine stack
        Variables     :    3860 bytes*
            Reads     :     114 [1.16e-03 ~ 0.0%]
            Writes    :     317 [3.96e-03 ~ 0.0%]
        Spills        :    3512 bytes*
            Reads     :     672 [2.64e+01 ~ 26.4%]
            Writes    :     454 [1.49e-02 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel052(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel052(const char *, ops_block, int, int *, ops_arg, ops_arg)) [57] ./MPI_OpenMP/opensbliblock00Kernel052_cpu_kernel.cpp(10,30)
  -> INLINE: (98,97) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,92) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,58) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,74) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,17) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,35) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel052_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel052_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel052_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel052_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel052_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel052_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel052_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel052PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel052_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   29[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm13 k1]
        
    Routine temporaries
        Total         :     344
            Global    :      76
            Local     :     268
        Regenerable   :     108
        Spilled       :      23
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [4.20e-04 ~ 0.0%]
            Writes    :      17 [1.55e-03 ~ 0.0%]
        Spills        :     224 bytes*
            Reads     :      59 [1.18e-02 ~ 0.0%]
            Writes    :      42 [9.28e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel053(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel053(const char *, ops_block, int, int *, ops_arg, ops_arg)) [58] ./MPI_OpenMP/opensbliblock00Kernel053_cpu_kernel.cpp(10,30)
  -> INLINE: (98,97) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,92) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,39) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,57) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,72) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,14) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel053_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel053_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel053_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel053_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel053_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel053_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel053_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel053PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel053_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   28[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm12 k1]
        
    Routine temporaries
        Total         :     338
            Global    :      74
            Local     :     264
        Regenerable   :     106
        Spilled       :      23
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [4.61e-04 ~ 0.0%]
            Writes    :      17 [1.70e-03 ~ 0.0%]
        Spills        :     224 bytes*
            Reads     :      58 [1.25e-02 ~ 0.0%]
            Writes    :      43 [1.02e-02 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel055(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel055(const char *, ops_block, int, int *, ops_arg, ops_arg)) [59] ./MPI_OpenMP/opensbliblock00Kernel055_cpu_kernel.cpp(10,30)
  -> INLINE: (98,97) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,92) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,38) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,55) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,71) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,14) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel055_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel055_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel055_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel055_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel055_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel055_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel055_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel055PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel055_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   29[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm13 k1]
        
    Routine temporaries
        Total         :     339
            Global    :      74
            Local     :     265
        Regenerable   :     106
        Spilled       :      23
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [4.50e-04 ~ 0.0%]
            Writes    :      17 [1.66e-03 ~ 0.0%]
        Spills        :     224 bytes*
            Reads     :      59 [1.26e-02 ~ 0.0%]
            Writes    :      42 [9.94e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel056(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel056(const char *, ops_block, int, int *, ops_arg, ops_arg)) [60] ./MPI_OpenMP/opensbliblock00Kernel056_cpu_kernel.cpp(10,30)
  -> INLINE: (98,97) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,92) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,38) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,56) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,74) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,17) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,33) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel056_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel056_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel056_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel056_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel056_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel056_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel056_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel056PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel056_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   28[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm12 k1]
        
    Routine temporaries
        Total         :     343
            Global    :      75
            Local     :     268
        Regenerable   :     107
        Spilled       :      24
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [4.20e-04 ~ 0.0%]
            Writes    :      17 [1.55e-03 ~ 0.0%]
        Spills        :     232 bytes*
            Reads     :      60 [1.22e-02 ~ 0.0%]
            Writes    :      45 [1.01e-02 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel057(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel057(const char *, ops_block, int, int *, ops_arg, ops_arg)) [61] ./MPI_OpenMP/opensbliblock00Kernel057_cpu_kernel.cpp(10,30)
  -> INLINE: (98,97) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,92) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,58) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,74) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,17) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,35) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel057_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel057_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel057_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel057_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel057_cpu_kernel.cpp(101,42):remark #34060: alignment of adjacent dense (unit-strided stencil) loads is (alignment, offset): (1, 0)
./MPI_OpenMP/opensbliblock00Kernel057_cpu_kernel.cpp(101,42):remark #34050: adjacent dense (unit-strided stencil) loads seem unprofitable to optimize.
./MPI_OpenMP/opensbliblock00Kernel057_cpu_kernel.cpp(101,74):remark #34060: alignment of adjacent dense (unit-strided stencil) loads is (alignment, offset): (1, 0)
./MPI_OpenMP/opensbliblock00Kernel057_cpu_kernel.cpp(101,74):remark #34050: adjacent dense (unit-strided stencil) loads seem unprofitable to optimize.
./MPI_OpenMP/opensbliblock00Kernel057_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel057_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel057_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel057PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel057_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   30[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm14 k1]
        
    Routine temporaries
        Total         :     340
            Global    :      75
            Local     :     265
        Regenerable   :     108
        Spilled       :      20
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.94e-04 ~ 0.0%]
            Writes    :      17 [1.45e-03 ~ 0.0%]
        Spills        :     200 bytes*
            Reads     :      49 [8.84e-03 ~ 0.0%]
            Writes    :      34 [6.52e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel058(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel058(const char *, ops_block, int, int *, ops_arg, ops_arg)) [62] ./MPI_OpenMP/opensbliblock00Kernel058_cpu_kernel.cpp(10,30)
  -> INLINE: (98,97) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,92) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,38) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,55) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,71) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,14) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel058_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel058_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel058_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel058_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel058_cpu_kernel.cpp(101,38):remark #34060: alignment of adjacent dense (unit-strided stencil) loads is (alignment, offset): (1, 0)
./MPI_OpenMP/opensbliblock00Kernel058_cpu_kernel.cpp(101,38):remark #34050: adjacent dense (unit-strided stencil) loads seem unprofitable to optimize.
./MPI_OpenMP/opensbliblock00Kernel058_cpu_kernel.cpp(101,38):remark #34060: alignment of adjacent dense (unit-strided stencil) loads is (alignment, offset): (1, 0)
./MPI_OpenMP/opensbliblock00Kernel058_cpu_kernel.cpp(101,38):remark #34050: adjacent dense (unit-strided stencil) loads seem unprofitable to optimize.
./MPI_OpenMP/opensbliblock00Kernel058_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel058_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel058_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel058PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel058_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   29[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm13 k1]
        
    Routine temporaries
        Total         :     335
            Global    :      73
            Local     :     262
        Regenerable   :     106
        Spilled       :      21
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [4.20e-04 ~ 0.0%]
            Writes    :      17 [1.55e-03 ~ 0.0%]
        Spills        :     208 bytes*
            Reads     :      49 [9.43e-03 ~ 0.0%]
            Writes    :      34 [6.95e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel059(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel059(const char *, ops_block, int, int *, ops_arg, ops_arg)) [63] ./MPI_OpenMP/opensbliblock00Kernel059_cpu_kernel.cpp(10,30)
  -> INLINE: (98,97) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,92) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,58) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,74) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,17) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,35) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel059_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel059_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel059_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel059_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel059_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel059_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel059_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel059PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel059_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   29[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm13 k1]
        
    Routine temporaries
        Total         :     346
            Global    :      76
            Local     :     270
        Regenerable   :     108
        Spilled       :      25
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [4.20e-04 ~ 0.0%]
            Writes    :      17 [1.55e-03 ~ 0.0%]
        Spills        :     240 bytes*
            Reads     :      60 [1.19e-02 ~ 0.0%]
            Writes    :      43 [9.71e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel060(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel060(const char *, ops_block, int, int *, ops_arg, ops_arg)) [64] ./MPI_OpenMP/opensbliblock00Kernel060_cpu_kernel.cpp(10,30)
  -> INLINE: (98,97) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,92) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,60) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,15) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,31) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,46) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel060_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel060_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel060_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel060_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel060_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel060_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel060_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel060PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel060_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   31[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm15 k1]
        
    Routine temporaries
        Total         :     346
            Global    :      75
            Local     :     271
        Regenerable   :     107
        Spilled       :      25
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [4.11e-04 ~ 0.0%]
            Writes    :      17 [1.51e-03 ~ 0.0%]
        Spills        :     240 bytes*
            Reads     :      59 [1.12e-02 ~ 0.0%]
            Writes    :      44 [9.53e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel061(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel061(const char *, ops_block, int, int *, ops_arg, ops_arg)) [65] ./MPI_OpenMP/opensbliblock00Kernel061_cpu_kernel.cpp(10,30)
  -> INLINE: (98,97) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,92) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,39) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,57) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,14) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,30) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel061_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel061_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel061_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel061_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel061_cpu_kernel.cpp(101,39):remark #34060: alignment of adjacent dense (unit-strided stencil) loads is (alignment, offset): (1, 0)
./MPI_OpenMP/opensbliblock00Kernel061_cpu_kernel.cpp(101,39):remark #34050: adjacent dense (unit-strided stencil) loads seem unprofitable to optimize.
./MPI_OpenMP/opensbliblock00Kernel061_cpu_kernel.cpp(101,57):remark #34060: alignment of adjacent dense (unit-strided stencil) loads is (alignment, offset): (1, 0)
./MPI_OpenMP/opensbliblock00Kernel061_cpu_kernel.cpp(101,57):remark #34050: adjacent dense (unit-strided stencil) loads seem unprofitable to optimize.
./MPI_OpenMP/opensbliblock00Kernel061_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel061_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel061_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel061PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel061_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   28[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm12 k1]
        
    Routine temporaries
        Total         :     334
            Global    :      73
            Local     :     261
        Regenerable   :     106
        Spilled       :      21
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [4.30e-04 ~ 0.0%]
            Writes    :      17 [1.58e-03 ~ 0.0%]
        Spills        :     208 bytes*
            Reads     :      49 [9.64e-03 ~ 0.0%]
            Writes    :      34 [7.11e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel062(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel062(const char *, ops_block, int, int *, ops_arg, ops_arg)) [66] ./MPI_OpenMP/opensbliblock00Kernel062_cpu_kernel.cpp(10,30)
  -> INLINE: (98,97) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,40) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,58) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,73) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,16) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel062_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel062_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel062_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel062_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel062_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel062_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel062_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel062PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel062_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   28[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm12 k1]
        
    Routine temporaries
        Total         :     340
            Global    :      74
            Local     :     266
        Regenerable   :     106
        Spilled       :      24
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [4.61e-04 ~ 0.0%]
            Writes    :      17 [1.70e-03 ~ 0.0%]
        Spills        :     232 bytes*
            Reads     :      59 [1.26e-02 ~ 0.0%]
            Writes    :      44 [1.07e-02 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel063(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel063(const char *, ops_block, int, int *, ops_arg, ops_arg)) [67] ./MPI_OpenMP/opensbliblock00Kernel063_cpu_kernel.cpp(10,30)
  -> INLINE: (98,97) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,40) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,58) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,74) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,16) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel063_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel063_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel063_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel063_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel063_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel063_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel063_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel063PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel063_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   27[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm11 k1]
        
    Routine temporaries
        Total         :     339
            Global    :      74
            Local     :     265
        Regenerable   :     106
        Spilled       :      24
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [4.73e-04 ~ 0.0%]
            Writes    :      17 [1.74e-03 ~ 0.0%]
        Spills        :     232 bytes*
            Reads     :      58 [1.25e-02 ~ 0.0%]
            Writes    :      41 [1.00e-02 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel065(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel065(const char *, ops_block, int, int *, ops_arg, ops_arg)) [68] ./MPI_OpenMP/opensbliblock00Kernel065_cpu_kernel.cpp(10,30)
  -> INLINE: (98,97) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,43) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,59) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,12) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,30) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,48) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel065_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel065_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel065_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel065_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel065_cpu_kernel.cpp(101,43):remark #34060: alignment of adjacent dense (unit-strided stencil) loads is (alignment, offset): (1, 0)
./MPI_OpenMP/opensbliblock00Kernel065_cpu_kernel.cpp(101,43):remark #34050: adjacent dense (unit-strided stencil) loads seem unprofitable to optimize.
./MPI_OpenMP/opensbliblock00Kernel065_cpu_kernel.cpp(102,12):remark #34060: alignment of adjacent dense (unit-strided stencil) loads is (alignment, offset): (1, 0)
./MPI_OpenMP/opensbliblock00Kernel065_cpu_kernel.cpp(102,12):remark #34050: adjacent dense (unit-strided stencil) loads seem unprofitable to optimize.
./MPI_OpenMP/opensbliblock00Kernel065_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel065_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel065_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel065PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel065_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   29[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm13 k1]
        
    Routine temporaries
        Total         :     338
            Global    :      74
            Local     :     264
        Regenerable   :     107
        Spilled       :      21
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [4.02e-04 ~ 0.0%]
            Writes    :      17 [1.48e-03 ~ 0.0%]
        Spills        :     208 bytes*
            Reads     :      49 [9.02e-03 ~ 0.0%]
            Writes    :      34 [6.66e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel066(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel066(const char *, ops_block, int, int *, ops_arg, ops_arg)) [69] ./MPI_OpenMP/opensbliblock00Kernel066_cpu_kernel.cpp(10,30)
  -> INLINE: (98,97) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,39) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,57) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,15) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,30) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,49) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel066_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel066_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel066_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel066_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel066_cpu_kernel.cpp(101,39):remark #34060: alignment of adjacent dense (unit-strided stencil) loads is (alignment, offset): (1, 0)
./MPI_OpenMP/opensbliblock00Kernel066_cpu_kernel.cpp(101,39):remark #34050: adjacent dense (unit-strided stencil) loads seem unprofitable to optimize.
./MPI_OpenMP/opensbliblock00Kernel066_cpu_kernel.cpp(101,39):remark #34060: alignment of adjacent dense (unit-strided stencil) loads is (alignment, offset): (1, 0)
./MPI_OpenMP/opensbliblock00Kernel066_cpu_kernel.cpp(101,39):remark #34050: adjacent dense (unit-strided stencil) loads seem unprofitable to optimize.
./MPI_OpenMP/opensbliblock00Kernel066_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel066_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel066_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel066PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel066_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   29[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm13 k1]
        
    Routine temporaries
        Total         :     339
            Global    :      74
            Local     :     265
        Regenerable   :     107
        Spilled       :      21
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.94e-04 ~ 0.0%]
            Writes    :      17 [1.45e-03 ~ 0.0%]
        Spills        :     208 bytes*
            Reads     :      49 [8.84e-03 ~ 0.0%]
            Writes    :      34 [6.52e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel067(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel067(const char *, ops_block, int, int *, ops_arg, ops_arg)) [70] ./MPI_OpenMP/opensbliblock00Kernel067_cpu_kernel.cpp(10,30)
  -> INLINE: (98,97) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,59) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,12) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,28) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel067_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel067_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel067_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel067_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel067_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel067_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel067_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel067PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel067_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   28[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm12 k1]
        
    Routine temporaries
        Total         :     337
            Global    :      74
            Local     :     263
        Regenerable   :     106
        Spilled       :      23
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [4.73e-04 ~ 0.0%]
            Writes    :      17 [1.74e-03 ~ 0.0%]
        Spills        :     224 bytes*
            Reads     :      58 [1.28e-02 ~ 0.0%]
            Writes    :      43 [1.05e-02 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel068(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel068(const char *, ops_block, int, int *, ops_arg, ops_arg)) [71] ./MPI_OpenMP/opensbliblock00Kernel068_cpu_kernel.cpp(10,30)
  -> INLINE: (98,96) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,38) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,55) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,72) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,13) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,31) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel068_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel068_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel068_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel068_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel068_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel068_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel068_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel068PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel068_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   28[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm12 k1]
        
    Routine temporaries
        Total         :     345
            Global    :      75
            Local     :     270
        Regenerable   :     107
        Spilled       :      25
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [4.20e-04 ~ 0.0%]
            Writes    :      17 [1.55e-03 ~ 0.0%]
        Spills        :     240 bytes*
            Reads     :      59 [1.15e-02 ~ 0.0%]
            Writes    :      44 [9.75e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel070(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel070(const char *, ops_block, int, int *, ops_arg, ops_arg)) [72] ./MPI_OpenMP/opensbliblock00Kernel070_cpu_kernel.cpp(10,30)
  -> INLINE: (98,96) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,57) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,72) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,14) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,31) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel070_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel070_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel070_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel070_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel070_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel070_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel070_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel070PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel070_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   29[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm13 k1]
        
    Routine temporaries
        Total         :     344
            Global    :      76
            Local     :     268
        Regenerable   :     108
        Spilled       :      23
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [4.20e-04 ~ 0.0%]
            Writes    :      17 [1.55e-03 ~ 0.0%]
        Spills        :     224 bytes*
            Reads     :      59 [1.18e-02 ~ 0.0%]
            Writes    :      42 [9.28e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel073(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel073(const char *, ops_block, int, int *, ops_arg, ops_arg)) [73] ./MPI_OpenMP/opensbliblock00Kernel073_cpu_kernel.cpp(10,30)
  -> INLINE: (98,97) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,43) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,59) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,12) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,30) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,48) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel073_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel073_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel073_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel073_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel073_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel073_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel073_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel073PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel073_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   29[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm13 k1]
        
    Routine temporaries
        Total         :     344
            Global    :      76
            Local     :     268
        Regenerable   :     108
        Spilled       :      23
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [4.20e-04 ~ 0.0%]
            Writes    :      17 [1.55e-03 ~ 0.0%]
        Spills        :     224 bytes*
            Reads     :      59 [1.18e-02 ~ 0.0%]
            Writes    :      42 [9.28e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel074(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel074(const char *, ops_block, int, int *, ops_arg, ops_arg)) [74] ./MPI_OpenMP/opensbliblock00Kernel074_cpu_kernel.cpp(10,30)
  -> INLINE: (98,97) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,39) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,57) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,15) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,31) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,50) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel074_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel074_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel074_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel074_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel074_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel074_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel074_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel074PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel074_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   28[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm12 k1]
        
    Routine temporaries
        Total         :     345
            Global    :      75
            Local     :     270
        Regenerable   :     107
        Spilled       :      25
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [4.20e-04 ~ 0.0%]
            Writes    :      17 [1.55e-03 ~ 0.0%]
        Spills        :     240 bytes*
            Reads     :      59 [1.15e-02 ~ 0.0%]
            Writes    :      44 [9.75e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel076(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel076(const char *, ops_block, int, int *, ops_arg, ops_arg)) [75] ./MPI_OpenMP/opensbliblock00Kernel076_cpu_kernel.cpp(10,30)
  -> INLINE: (98,97) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,57) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,14) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,30) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel076_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel076_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel076_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel076_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel076_cpu_kernel.cpp(101,42):remark #34060: alignment of adjacent dense (unit-strided stencil) loads is (alignment, offset): (1, 0)
./MPI_OpenMP/opensbliblock00Kernel076_cpu_kernel.cpp(101,42):remark #34050: adjacent dense (unit-strided stencil) loads seem unprofitable to optimize.
./MPI_OpenMP/opensbliblock00Kernel076_cpu_kernel.cpp(101,42):remark #34060: alignment of adjacent dense (unit-strided stencil) loads is (alignment, offset): (1, 0)
./MPI_OpenMP/opensbliblock00Kernel076_cpu_kernel.cpp(101,42):remark #34050: adjacent dense (unit-strided stencil) loads seem unprofitable to optimize.
./MPI_OpenMP/opensbliblock00Kernel076_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel076_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel076_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel076PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel076_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   27[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm11 k1]
        
    Routine temporaries
        Total         :     333
            Global    :      73
            Local     :     260
        Regenerable   :     106
        Spilled       :      21
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [4.40e-04 ~ 0.0%]
            Writes    :      17 [1.62e-03 ~ 0.0%]
        Spills        :     208 bytes*
            Reads     :      49 [9.86e-03 ~ 0.0%]
            Writes    :      34 [7.28e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel077(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel077(const char *, ops_block, int, int *, ops_arg, ops_arg)) [76] ./MPI_OpenMP/opensbliblock00Kernel077_cpu_kernel.cpp(10,30)
  -> INLINE: (98,96) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,57) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,72) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,14) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,31) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel077_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel077_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel077_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel077_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel077_cpu_kernel.cpp(101,42):remark #34060: alignment of adjacent dense (unit-strided stencil) loads is (alignment, offset): (1, 0)
./MPI_OpenMP/opensbliblock00Kernel077_cpu_kernel.cpp(101,42):remark #34050: adjacent dense (unit-strided stencil) loads seem unprofitable to optimize.
./MPI_OpenMP/opensbliblock00Kernel077_cpu_kernel.cpp(101,72):remark #34060: alignment of adjacent dense (unit-strided stencil) loads is (alignment, offset): (1, 0)
./MPI_OpenMP/opensbliblock00Kernel077_cpu_kernel.cpp(101,72):remark #34050: adjacent dense (unit-strided stencil) loads seem unprofitable to optimize.
./MPI_OpenMP/opensbliblock00Kernel077_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel077_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel077_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel077PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel077_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   30[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm14 k1]
        
    Routine temporaries
        Total         :     340
            Global    :      75
            Local     :     265
        Regenerable   :     108
        Spilled       :      20
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [3.94e-04 ~ 0.0%]
            Writes    :      17 [1.45e-03 ~ 0.0%]
        Spills        :     200 bytes*
            Reads     :      49 [8.84e-03 ~ 0.0%]
            Writes    :      34 [6.52e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel078(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel078(const char *, ops_block, int, int *, ops_arg, ops_arg)) [77] ./MPI_OpenMP/opensbliblock00Kernel078_cpu_kernel.cpp(10,30)
  -> INLINE: (98,97) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,39) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,56) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,71) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,14) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel078_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel078_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel078_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel078_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel078_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel078_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel078_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel078PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel078_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   28[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm12 k1]
        
    Routine temporaries
        Total         :     340
            Global    :      74
            Local     :     266
        Regenerable   :     106
        Spilled       :      24
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [4.61e-04 ~ 0.0%]
            Writes    :      17 [1.70e-03 ~ 0.0%]
        Spills        :     232 bytes*
            Reads     :      59 [1.26e-02 ~ 0.0%]
            Writes    :      44 [1.07e-02 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel054(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel054(const char *, ops_block, int, int *, ops_arg, ops_arg)) [78] ./MPI_OpenMP/opensbliblock00Kernel054_cpu_kernel.cpp(10,30)
  -> INLINE: (98,98) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,92) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,60) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,13) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,30) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel054_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel054_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel054_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel054_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel054_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel054_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel054_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel054PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel054_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   28[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm12 k1]
        
    Routine temporaries
        Total         :     337
            Global    :      74
            Local     :     263
        Regenerable   :     106
        Spilled       :      23
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [4.73e-04 ~ 0.0%]
            Writes    :      17 [1.74e-03 ~ 0.0%]
        Spills        :     224 bytes*
            Reads     :      58 [1.28e-02 ~ 0.0%]
            Writes    :      43 [1.05e-02 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel064(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel064(const char *, ops_block, int, int *, ops_arg, ops_arg)) [79] ./MPI_OpenMP/opensbliblock00Kernel064_cpu_kernel.cpp(10,30)
  -> INLINE: (98,98) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,41) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,60) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,15) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,31) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel064_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel064_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel064_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel064_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel064_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel064_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel064_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel064PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel064_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   27[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm11 k1]
        
    Routine temporaries
        Total         :     339
            Global    :      74
            Local     :     265
        Regenerable   :     106
        Spilled       :      24
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [4.73e-04 ~ 0.0%]
            Writes    :      17 [1.74e-03 ~ 0.0%]
        Spills        :     232 bytes*
            Reads     :      58 [1.25e-02 ~ 0.0%]
            Writes    :      41 [1.00e-02 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel069(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel069(const char *, ops_block, int, int *, ops_arg, ops_arg)) [80] ./MPI_OpenMP/opensbliblock00Kernel069_cpu_kernel.cpp(10,30)
  -> INLINE: (98,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,62) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,16) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,33) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel069_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel069_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel069_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel069_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel069_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel069_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel069_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel069PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel069_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   27[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm11 k1]
        
    Routine temporaries
        Total         :     339
            Global    :      74
            Local     :     265
        Regenerable   :     106
        Spilled       :      24
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [4.73e-04 ~ 0.0%]
            Writes    :      17 [1.74e-03 ~ 0.0%]
        Spills        :     232 bytes*
            Reads     :      58 [1.25e-02 ~ 0.0%]
            Writes    :      41 [1.00e-02 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel071(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel071(const char *, ops_block, int, int *, ops_arg, ops_arg)) [81] ./MPI_OpenMP/opensbliblock00Kernel071_cpu_kernel.cpp(10,30)
  -> INLINE: (98,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,42) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,62) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,14) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,33) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel071_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel071_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel071_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel071_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel071_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel071_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel071_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel071PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel071_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   28[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm12 k1]
        
    Routine temporaries
        Total         :     340
            Global    :      74
            Local     :     266
        Regenerable   :     106
        Spilled       :      24
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [4.61e-04 ~ 0.0%]
            Writes    :      17 [1.70e-03 ~ 0.0%]
        Spills        :     232 bytes*
            Reads     :      59 [1.26e-02 ~ 0.0%]
            Writes    :      44 [1.07e-02 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel072(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel072(const char *, ops_block, int, int *, ops_arg, ops_arg)) [82] ./MPI_OpenMP/opensbliblock00Kernel072_cpu_kernel.cpp(10,30)
  -> INLINE: (98,98) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,41) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,58) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,15) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,34) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel072_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel072_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel072_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel072_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel072_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel072_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel072_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel072PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel072_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   29[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm13 k1]
        
    Routine temporaries
        Total         :     341
            Global    :      74
            Local     :     267
        Regenerable   :     106
        Spilled       :      24
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [4.50e-04 ~ 0.0%]
            Writes    :      17 [1.66e-03 ~ 0.0%]
        Spills        :     232 bytes*
            Reads     :      58 [1.19e-02 ~ 0.0%]
            Writes    :      41 [9.52e-03 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel075(const char *, ops_block, int, int *, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel075(const char *, ops_block, int, int *, ops_arg, ops_arg)) [83] ./MPI_OpenMP/opensbliblock00Kernel075_cpu_kernel.cpp(10,30)
  -> INLINE: (98,98) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (99,93) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (101,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (101,43) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (101,61) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,13) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (102,30) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel075_cpu_kernel.cpp(84,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel075_cpu_kernel.cpp(85,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel075_cpu_kernel.cpp(97,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel075_cpu_kernel.cpp(97,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel075_cpu_kernel.cpp(23,23):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel075_cpu_kernel.cpp(23,29):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel075_cpu_kernel.cpp(10,30):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel075PKcP14ops_block_coreiPi7ops_argS4_] ./MPI_OpenMP/opensbliblock00Kernel075_cpu_kernel.cpp:10

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   28[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm12 k1]
        
    Routine temporaries
        Total         :     337
            Global    :      74
            Local     :     263
        Regenerable   :     106
        Spilled       :      23
        
    Routine stack
        Variables     :     260 bytes*
            Reads     :      14 [4.73e-04 ~ 0.0%]
            Writes    :      17 [1.74e-03 ~ 0.0%]
        Spills        :     224 bytes*
            Reads     :      58 [1.28e-02 ~ 0.0%]
            Writes    :      43 [1.05e-02 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel080(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel080(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)) [84] ./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(18,32)
  -> INLINE: (298,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (299,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (300,97) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (301,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (302,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (303,98) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (304,97) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (305,98) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (306,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (307,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (308,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (309,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (310,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (311,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (312,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (313,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (314,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (315,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (316,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (317,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (318,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (319,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (320,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (321,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (322,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (323,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (324,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (325,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (326,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (327,101) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (328,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (329,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (330,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (331,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (333,17) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (333,53) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (333,77) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (334,21) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (334,37) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (334,53) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (335,19) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (337,17) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (337,52) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (337,76) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (338,14) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (338,37) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (338,53) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (339,19) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (341,17) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (341,53) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (341,70) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (342,21) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (342,38) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (342,61) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (343,19) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (345,17) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (345,70) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (346,14) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (346,31) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (346,61) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (347,14) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (347,30) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (347,59) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (348,14) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (348,30) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (348,59) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (349,14) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (349,30) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (349,59) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (350,14) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (350,30) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (350,58) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (351,13) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (351,28) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (351,56) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (352,13) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (352,28) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (352,62) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (353,17) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (353,40) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (353,55) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (354,31) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (354,54) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (355,17) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (355,32) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (355,68) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (356,17) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (356,37) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (356,53) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (357,32) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (357,56) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (357,73) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (358,20) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (358,36) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (358,50) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (359,33) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (359,50) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (359,74) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (360,14) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (360,37) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (360,51) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (361,33) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (361,57) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (361,81) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (362,15) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (362,31) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (362,45) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (362,67) ACC<double>::operator()(ACC<double> *, int, int, int)


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(284,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(285,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(297,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(297,7)
   <Remainder loop for vectorization>
      remark #15301: REMAINDER LOOP WAS VECTORIZED
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,24):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,30):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,36):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,42):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,48):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,54):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,60):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,66):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,72):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,78):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,84):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,91):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,98):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,105):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,112):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,119):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,126):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,133):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,140):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,147):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,154):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,161):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,168):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,175):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,182):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,189):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,196):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,203):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,210):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,217):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,224):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,231):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,238):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(63,245):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp(18,32):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel080PKcP14ops_block_coreiPi7ops_argS4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_] ./MPI_OpenMP/opensbliblock00Kernel080_cpu_kernel.cpp:18

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   47[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm31 k1]
        
    Routine temporaries
        Total         :    1951
            Global    :     349
            Local     :    1602
        Regenerable   :     430
        Spilled       :     263
        
    Routine stack
        Variables     :    2564 bytes*
            Reads     :      78 [3.80e-04 ~ 0.0%]
            Writes    :     209 [1.30e-03 ~ 0.0%]
        Spills        :    2144 bytes*
            Reads     :     445 [2.74e+01 ~ 27.4%]
            Writes    :     295 [4.32e+00 ~ 4.3%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel090(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel090(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)) [85] ./MPI_OpenMP/opensbliblock00Kernel090_cpu_kernel.cpp(13,62)
  -> INLINE: (183,104) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (184,104) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (185,106) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (186,104) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (187,104) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (188,104) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (189,104) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (190,105) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (191,106) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (192,106) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (193,95) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (194,96) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (195,94) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (196,96) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (197,96) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (199,10) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (199,44) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (199,66) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (201,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (201,46) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (201,70) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (203,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (203,46) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (203,70) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (205,12) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (205,46) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (205,70) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (207,11) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (207,45) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (207,68) ACC<double>::operator()(const ACC<double> *, int, int, int) const


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel090_cpu_kernel.cpp(169,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel090_cpu_kernel.cpp(170,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel090_cpu_kernel.cpp(182,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel090_cpu_kernel.cpp(182,7)
   <Remainder loop for vectorization>
      remark #15335: remainder loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel090_cpu_kernel.cpp(40,24):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel090_cpu_kernel.cpp(40,30):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel090_cpu_kernel.cpp(40,36):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel090_cpu_kernel.cpp(40,42):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel090_cpu_kernel.cpp(40,48):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel090_cpu_kernel.cpp(40,54):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel090_cpu_kernel.cpp(40,60):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel090_cpu_kernel.cpp(40,66):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel090_cpu_kernel.cpp(40,72):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel090_cpu_kernel.cpp(40,78):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel090_cpu_kernel.cpp(40,84):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel090_cpu_kernel.cpp(40,91):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel090_cpu_kernel.cpp(40,98):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel090_cpu_kernel.cpp(40,105):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel090_cpu_kernel.cpp(40,112):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel090_cpu_kernel.cpp(40,119):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel090_cpu_kernel.cpp(13,62):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel090PKcP14ops_block_coreiPi7ops_argS4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_] ./MPI_OpenMP/opensbliblock00Kernel090_cpu_kernel.cpp:13

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   46[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm31]
        
    Routine temporaries
        Total         :     934
            Global    :     198
            Local     :     736
        Regenerable   :     243
        Spilled       :     122
        
    Routine stack
        Variables     :    1260 bytes*
            Reads     :      41 [2.13e-03 ~ 0.0%]
            Writes    :      99 [7.40e-03 ~ 0.0%]
        Spills        :    1016 bytes*
            Reads     :     197 [1.48e+01 ~ 14.8%]
            Writes    :     135 [2.62e-02 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_par_loop_opensbliblock00Kernel089(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_par_loop_opensbliblock00Kernel089(const char *, ops_block, int, int *, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg, ops_arg)) [86] ./MPI_OpenMP/opensbliblock00Kernel089_cpu_kernel.cpp(12,45)
  -> INLINE: (152,104) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (153,104) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (154,104) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (155,104) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (156,104) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (157,98) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (158,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (159,99) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (160,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (161,100) ACC<double>::ACC(ACC<double> *, int, int, double *)
  -> INLINE: (163,16) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (163,50) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (163,72) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (165,18) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (165,52) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (165,76) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (167,18) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (167,52) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (167,76) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (169,18) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (169,52) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (169,76) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (171,17) ACC<double>::operator()(ACC<double> *, int, int, int)
  -> INLINE: (171,51) ACC<double>::operator()(const ACC<double> *, int, int, int) const
  -> INLINE: (171,74) ACC<double>::operator()(ACC<double> *, int, int, int)


    Report from: OpenMP optimizations [openmp]

OpenMP Construct at ./MPI_OpenMP/opensbliblock00Kernel089_cpu_kernel.cpp(138,3)
remark #16201: OpenMP DEFINED REGION WAS PARALLELIZED

    Report from: Loop nest, Vector & Auto-parallelization optimizations [loop, vec, par]


LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel089_cpu_kernel.cpp(139,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel089_cpu_kernel.cpp(151,7)
      remark #25236: Loop with pragma of trip count = 10000 ignored for large value
      remark #15301: SIMD LOOP WAS VECTORIZED
      remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override
   LOOP END

   LOOP BEGIN at ./MPI_OpenMP/opensbliblock00Kernel089_cpu_kernel.cpp(151,7)
   <Remainder loop for vectorization>
      remark #15335: remainder loop was not vectorized: vectorization possible but seems inefficient. Use vector always directive or -vec-threshold0 to override 
   LOOP END
LOOP END

    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbliblock00Kernel089_cpu_kernel.cpp(34,24):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel089_cpu_kernel.cpp(34,30):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel089_cpu_kernel.cpp(34,36):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel089_cpu_kernel.cpp(34,42):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel089_cpu_kernel.cpp(34,48):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel089_cpu_kernel.cpp(34,54):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel089_cpu_kernel.cpp(34,60):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel089_cpu_kernel.cpp(34,66):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 8)
./MPI_OpenMP/opensbliblock00Kernel089_cpu_kernel.cpp(34,72):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 0)
./MPI_OpenMP/opensbliblock00Kernel089_cpu_kernel.cpp(34,78):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 24)
./MPI_OpenMP/opensbliblock00Kernel089_cpu_kernel.cpp(34,84):remark #34000: call to memcpy implemented inline with loads and stores with proven source (alignment, offset): (8, 0), and destination (alignment, offset): (32, 16)
./MPI_OpenMP/opensbliblock00Kernel089_cpu_kernel.cpp(12,45):remark #34051: REGISTER ALLOCATION : [_Z37ops_par_loop_opensbliblock00Kernel089PKcP14ops_block_coreiPi7ops_argS4_S4_S4_S4_S4_S4_S4_S4_S4_S4_] ./MPI_OpenMP/opensbliblock00Kernel089_cpu_kernel.cpp:12

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :   36[ rax rdx rcx rbx rsi rdi r8-r15 zmm0-zmm21]
        
    Routine temporaries
        Total         :     709
            Global    :     150
            Local     :     559
        Regenerable   :     194
        Spilled       :      78
        
    Routine stack
        Variables     :     900 bytes*
            Reads     :      31 [1.50e-03 ~ 0.0%]
            Writes    :      69 [5.27e-03 ~ 0.0%]
        Spills        :     664 bytes*
            Reads     :     139 [3.80e+00 ~ 3.8%]
            Writes    :      95 [1.85e-02 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ACC<double>::ACC(ACC<double> *, int, int, double *)

    Report from: Interprocedural optimizations [ipo]

DEAD STATIC FUNCTION: (ACC<double>::ACC(ACC<double> *, int, int, double *)) /home/reguly/OPS/ops/c/include/ops_lib_core.h(1361,82)

===========================================================================

Begin optimization report for: ACC<double>::operator()(const ACC<double> *, int, int, int) const

    Report from: Interprocedural optimizations [ipo]

DEAD STATIC FUNCTION: (ACC<double>::operator()(const ACC<double> *, int, int, int) const) /home/reguly/OPS/ops/c/include/ops_lib_core.h(1372,59)

===========================================================================

Begin optimization report for: ACC<double>::operator()(ACC<double> *, int, int, int)

    Report from: Interprocedural optimizations [ipo]

DEAD STATIC FUNCTION: (ACC<double>::operator()(ACC<double> *, int, int, int)) /home/reguly/OPS/ops/c/include/ops_lib_core.h(1374,47)

===========================================================================

Begin optimization report for: std::pow<double, int>(double, int)

    Report from: Code generation optimizations [cg]

/usr/include/c++/8/cmath(416,5):remark #34051: REGISTER ALLOCATION : [_ZSt3powIdiEN9__gnu_cxx11__promote_2IT_T0_NS0_9__promoteIS2_Xsr3std12__is_integerIS2_EE7__valueEE6__typeENS4_IS3_Xsr3std12__is_integerIS3_EE7__valueEE6__typeEE6__typeES2_S3_] /usr/include/c++/8/cmath:416

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    3[ rdi zmm0-zmm1]
        
    Routine temporaries
        Total         :      16
            Global    :       7
            Local     :       9
        Regenerable   :       0
        Spilled       :       0
        
    Routine stack
        Variables     :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: __sti__$E()

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (__sti__$E()) [113] <compiler generated>


    Report from: Code generation optimizations [cg]

<compiler generated>:remark #34051: REGISTER ALLOCATION : [__sti__$E] (null):0

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    3[ rdx rsi rdi]
        
    Routine temporaries
        Total         :      13
            Global    :       7
            Local     :       6
        Regenerable   :       7
        Spilled       :       0
        
    Routine stack
        Variables     :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================

Begin optimization report for: ops_init_backend()

    Report from: Interprocedural optimizations [ipo]

INLINE REPORT: (ops_init_backend()) [114] ./MPI_OpenMP/opensbli_cpu_kernels.cpp(41,25)


    Report from: Code generation optimizations [cg]

./MPI_OpenMP/opensbli_cpu_kernels.cpp(41,25):remark #34051: REGISTER ALLOCATION : [_Z16ops_init_backendv] ./MPI_OpenMP/opensbli_cpu_kernels.cpp:41

    Hardware registers
        Reserved     :    2[ rsp rip]
        Available    :   63[ rax rdx rcx rbx rbp rsi rdi r8-r15 mm0-mm7 zmm0-zmm31 k0-k7]
        Callee-save  :    6[ rbx rbp r12-r15]
        Assigned     :    0[ reg_null]
        
    Routine temporaries
        Total         :       6
            Global    :       0
            Local     :       6
        Regenerable   :       0
        Spilled       :       0
        
    Routine stack
        Variables     :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
        Spills        :       0 bytes*
            Reads     :       0 [0.00e+00 ~ 0.0%]
            Writes    :       0 [0.00e+00 ~ 0.0%]
    
    Notes
    
        *Non-overlapping variables and spills may share stack space,
         so the total stack size might be less than this.
    

===========================================================================
